<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Case-1 Debug â€“ Local LLM</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>

<style>
body {
  font-family: system-ui, sans-serif;
  background: #020617;
  color: #e5e7eb;
  padding: 20px;
}
button {
  padding: 12px 18px;
  font-size: 16px;
  cursor: pointer;
  margin-right: 10px;
}
#status {
  margin-top: 15px;
  font-weight: bold;
}
#progress {
  width: 100%;
  height: 14px;
  background: #1e293b;
  border-radius: 8px;
  overflow: hidden;
  margin-top: 10px;
}
#bar {
  height: 100%;
  width: 0%;
  background: #22c55e;
}
pre {
  background: #020617;
  border: 1px solid #1e293b;
  padding: 10px;
  margin-top: 15px;
  max-height: 300px;
  overflow-y: auto;
  font-size: 13px;
}
#errorBox {
  display: none;
  background: #7f1d1d;
  color: #fff;
  padding: 15px;
  border-radius: 8px;
  margin-top: 15px;
}
</style>
</head>

<body>

<h2>ðŸ§ª Case-1 Browser LLM â€“ Debug Mode</h2>

<button id="loadBtn">Load Model</button>
<button id="runBtn" disabled>Run Prompt</button>

<div id="status">Idle</div>

<div id="progress">
  <div id="bar"></div>
</div>

<div id="errorBox"></div>

<pre id="log"></pre>

<script type="module">
import { pipeline, env } from "https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2";

/* ============================================================
   FORCE SAFE EXECUTION
============================================================ */
env.allowLocalModels = false;
env.useBrowserCache = true;
env.backends.webgpu.enabled = false;
env.backends.wasm.enabled = true;
env.backends.onnx.wasm.numThreads = 1;

/* ============================================================
   UI HELPERS
============================================================ */
const logBox = document.getElementById("log");
const statusEl = document.getElementById("status");
const bar = document.getElementById("bar");
const errorBox = document.getElementById("errorBox");
const loadBtn = document.getElementById("loadBtn");
const runBtn = document.getElementById("runBtn");

function log(msg) {
  logBox.textContent += msg + "\n";
  logBox.scrollTop = logBox.scrollHeight;
}
function status(msg) {
  statusEl.textContent = msg;
  log("STATUS: " + msg);
}
function error(msg) {
  errorBox.style.display = "block";
  errorBox.textContent = msg;
  log("ERROR: " + msg);
}

/* ============================================================
   FETCH INTERCEPTOR â€“ DOWNLOAD PROGRESS
============================================================ */
const originalFetch = window.fetch;
window.fetch = async (...args) => {
  const response = await originalFetch(...args);

  if (!response.body || !response.headers.get("content-length")) {
    return response;
  }

  const total = parseInt(response.headers.get("content-length"), 10);
  let loaded = 0;

  const reader = response.body.getReader();
  const stream = new ReadableStream({
    start(controller) {
      function push() {
        reader.read().then(({ done, value }) => {
          if (done) {
            controller.close();
            return;
          }
          loaded += value.byteLength;
          const percent = Math.min(100, Math.round((loaded / total) * 100));
          bar.style.width = percent + "%";
          status(`Downloading modelâ€¦ ${percent}%`);
          controller.enqueue(value);
          push();
        }).catch(err => {
          error("Stream read failed: " + err.message);
        });
      }
      push();
    }
  });

  return new Response(stream, { headers: response.headers });
};

/* ============================================================
   LOAD MODEL
============================================================ */
let generator = null;

loadBtn.onclick = async () => {
  try {
    bar.style.width = "0%";
    errorBox.style.display = "none";
    status("Initializing pipelineâ€¦");

    generator = await pipeline(
      "text-generation",
      "Qwen/Qwen2-0.5B-Instruct",
      {
        device: "cpu",
        dtype: "q8"
      }
    );

    status("âœ… Model loaded successfully");
    runBtn.disabled = false;

  } catch (e) {
    error(e.message || String(e));
  }
};

/* ============================================================
   RUN PROMPT
============================================================ */
runBtn.onclick = async () => {
  try {
    status("Running inferenceâ€¦");

    const out = await generator(
      "User: Order two veg pizzas and one coke\nAssistant:",
      { max_new_tokens: 50 }
    );

    status("Inference complete");
    log(out[0].generated_text);

  } catch (e) {
    error(e.message || String(e));
  }
};
</script>

</body>
</html>
